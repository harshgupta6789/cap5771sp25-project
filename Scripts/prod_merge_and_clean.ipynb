{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from data_preprocess import DataPreprocessor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_delay_df = pd.read_csv('../Data/flights_sample_3m.csv')\n",
    "airline_codes_df = pd.read_csv('../Data/airline_codes.csv')\n",
    "airline_fleet_df = pd.read_csv('../Data/Fleet Data.csv')\n",
    "airline_prices_df = pd.read_csv('../Data/consumer_airfare.csv')\n",
    "# busiestairports_df = pd.read_csv('data/busiestAirports.csv', encoding='cp1252')\n",
    "# passenger_satisfaction_df = pd.read_excel('data/passenger_satisfaction.xlsx')\n",
    "storm_events_df = pd.read_csv('../Data/StormEvents_details-ftp_v1.0_d2020_c20240620.csv')\n",
    "international_report_departures_df = pd.read_csv('../Data/International_Report_Departures.csv')\n",
    "# international_report_passengers_df = pd.read_csv('../Data/international_report_passengers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = {\n",
    "    \"ALABAMA\": \"AL\",\n",
    "    \"ALASKA\": \"AK\",\n",
    "    \"ARIZONA\": \"AZ\",\n",
    "    \"ARKANSAS\": \"AR\",\n",
    "    \"CALIFORNIA\": \"CA\",\n",
    "    \"COLORADO\": \"CO\",\n",
    "    \"CONNECTICUT\": \"CT\",\n",
    "    \"DELAWARE\": \"DE\",\n",
    "    \"DISTRICT OF COLUMBIA\": \"DC\",\n",
    "    \"FLORIDA\": \"FL\",\n",
    "    \"GEORGIA\": \"GA\",\n",
    "    \"HAWAII\": \"HI\",\n",
    "    \"IDAHO\": \"ID\",\n",
    "    \"ILLINOIS\": \"IL\",\n",
    "    \"INDIANA\": \"IN\",\n",
    "    \"IOWA\": \"IA\",\n",
    "    \"KANSAS\": \"KS\",\n",
    "    \"KENTUCKY\": \"KY\",\n",
    "    \"LOUISIANA\": \"LA\",\n",
    "    \"MAINE\": \"ME\",\n",
    "    \"MARYLAND\": \"MD\",\n",
    "    \"MASSACHUSETTS\": \"MA\",\n",
    "    \"MICHIGAN\": \"MI\",\n",
    "    \"MINNESOTA\": \"MN\",\n",
    "    \"MISSISSIPPI\": \"MS\",\n",
    "    \"MISSOURI\": \"MO\",\n",
    "    \"MONTANA\": \"MT\",\n",
    "    \"NEBRASKA\": \"NE\",\n",
    "    \"NEVADA\": \"NV\",\n",
    "    \"NEW HAMPSHIRE\": \"NH\",\n",
    "    \"NEW JERSEY\": \"NJ\",\n",
    "    \"NEW MEXICO\": \"NM\",\n",
    "    \"NEW YORK\": \"NY\",\n",
    "    \"NORTH CAROLINA\": \"NC\",\n",
    "    \"NORTH DAKOTA\": \"ND\",\n",
    "    \"OHIO\": \"OH\",\n",
    "    \"OKLAHOMA\": \"OK\",\n",
    "    \"OREGON\": \"OR\",\n",
    "    \"PENNSYLVANIA\": \"PA\",\n",
    "    \"PUERTO RICO\": \"PR\",\n",
    "    \"RHODE ISLAND\": \"RI\",\n",
    "    \"SOUTH CAROLINA\": \"SC\",\n",
    "    \"SOUTH DAKOTA\": \"SD\",\n",
    "    \"TENNESSEE\": \"TN\",\n",
    "    \"TEXAS\": \"TX\",\n",
    "    \"UTAH\": \"UT\",\n",
    "    \"VERMONT\": \"VT\",\n",
    "    \"VIRGINIA\": \"VA\",\n",
    "    \"VIRGIN ISLANDS\": \"VI\",\n",
    "    \"WASHINGTON\": \"WA\",\n",
    "    \"WEST VIRGINIA\": \"WV\",\n",
    "    \"WISCONSIN\": \"WI\",\n",
    "    \"WYOMING\": \"WY\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storm_events_df['year'] = storm_events_df['BEGIN_YEARMONTH'].astype(str).str[:4].astype(int)\n",
    "# storm_events_df['month'] = storm_events_df['BEGIN_YEARMONTH'].astype(str).str[4:6].astype(int)\n",
    "# storm_events_df['day'] = storm_events_df['BEGIN_DAY'].astype(int)\n",
    "# storm_events_df['date'] = pd.to_datetime(storm_events_df[['year', 'month', 'day']])\n",
    "# storm_events_df.drop(columns=['year', 'month', 'day'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# international_report_departures_df['data_dte'] = international_report_departures_df['data_dte'].astype(str)\n",
    "# international_report_departures_df['date'] = pd.to_datetime(international_report_departures_df['data_dte'])\n",
    "\n",
    "international_report_departures_df['date'] = pd.to_datetime(\n",
    "    international_report_departures_df['data_dte'], format=\"%Y-%m-%d\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "storm_events_df['date'] = pd.to_datetime(storm_events_df['BEGIN_DATE_TIME'], format=\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_delay_df['FL_DATE'] = pd.to_datetime(airline_delay_df['FL_DATE'], format='%Y-%m-%d')\n",
    "airline_delay_df['year'] = airline_delay_df['FL_DATE'].dt.year\n",
    "international_report_departures_df['year'] = international_report_departures_df['date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_delay_df_2020 = airline_delay_df[airline_delay_df['FL_DATE'].dt.year == 2020]\n",
    "international_report_departures_df_2020 = international_report_departures_df[international_report_departures_df['date'].dt.year == 2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'FL_DATE', 'AIRLINE', 'AIRLINE_CODE', 'DOT_CODE',\n",
       "       'FL_NUMBER', 'ORIGIN', 'ORIGIN_CITY', 'DEST', 'DEST_CITY',\n",
       "       'CRS_DEP_TIME', 'DEP_DELAY', 'CRS_ARR_TIME', 'ARR_DELAY', 'CANCELLED',\n",
       "       'DIVERTED', 'CRS_ELAPSED_TIME', 'ELAPSED_TIME', 'AIR_TIME', 'DISTANCE',\n",
       "       'DELAY_DUE_CARRIER', 'DELAY_DUE_WEATHER', 'DELAY_DUE_NAS',\n",
       "       'DELAY_DUE_SECURITY', 'DELAY_DUE_LATE_AIRCRAFT', 'Month_Year', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_delay_df_2020.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vd/dmj076xx2t38kz00wdhlwgqh0000gn/T/ipykernel_92677/2125564179.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  airline_delay_df_2020.fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "airline_delay_df_2020.fillna(0, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = airline_delay_df_2020.merge(\n",
    "    international_report_departures_df_2020,\n",
    "    left_on=['FL_DATE', 'AIRLINE_CODE'],   # List format for multiple columns\n",
    "    right_on=['date', 'carrier'],         # List format for multiple columns\n",
    "    how='left'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['state'] = merged_df['DEST_CITY'].str.split(\", \").str[1]\n",
    "storm_events_df['STATE'] = storm_events_df['STATE'].map(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'BEGIN_DATE_TIME', 'END_DATE_TIME', 'STATE', 'EVENT_TYPE',\n",
       "       'MAGNITUDE', 'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT',\n",
       "       'DEATHS_INDIRECT', 'date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storm_events_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.merge(\n",
    "    storm_events_df,\n",
    "    left_on=['FL_DATE', 'state'],   # List format for multiple columns\n",
    "    right_on=['date', 'STATE'],         # List format for multiple columns\n",
    "    how='inner'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting relevant columns\n",
    "needed_columns = [\n",
    "'FL_DATE', 'AIRLINE_CODE', 'state','CRS_DEP_TIME',\n",
    "       'DEP_TIME', 'DEP_DELAY', 'CRS_ARR_TIME', 'ARR_TIME', 'ARR_DELAY',\n",
    "       'CANCELLED', 'DIVERTED', 'CRS_ELAPSED_TIME', 'DISTANCE',\n",
    "       'DELAY_DUE_CARRIER', 'DELAY_DUE_WEATHER', 'DELAY_DUE_NAS',\n",
    "       'DELAY_DUE_SECURITY', 'DELAY_DUE_LATE_AIRCRAFT',\n",
    "       'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT',\n",
    "       'DEATHS_INDIRECT', 'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'SOURCE',\n",
    "       'MAGNITUDE', 'MAGNITUDE_TYPE', 'FLOOD_CAUSE', 'CATEGORY', 'TOR_F_SCALE',\n",
    "       'TOR_LENGTH', 'TOR_WIDTH', 'TOR_OTHER_WFO', 'TOR_OTHER_CZ_STATE',\n",
    "       'TOR_OTHER_CZ_FIPS', 'TOR_OTHER_CZ_NAME', 'BEGIN_RANGE',\n",
    "       'BEGIN_AZIMUTH', 'BEGIN_LOCATION', 'END_RANGE', 'END_AZIMUTH',\n",
    "       'END_LOCATION', 'BEGIN_LAT', 'BEGIN_LON', 'END_LAT', 'END_LON',\n",
    "       'EPISODE_NARRATIVE', 'EVENT_NARRATIVE', 'DATA_SOURCE'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    TX\n",
       "Name: state, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['state'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df = merged_df[needed_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop rows where essential numerical columns are missing\n",
    "# airline_fleet_df.dropna(subset=['Current', 'Total', 'Average Age'], inplace=True)\n",
    "\n",
    "# # Fill missing values in 'Orders' and 'Future' with 0\n",
    "# airline_fleet_df[['Orders', 'Future']] = airline_fleet_df[['Orders', 'Future']].fillna(0)\n",
    "\n",
    "# # Fill missing categorical values with \"Unknown\"\n",
    "# airline_fleet_df[['Parent Airline', 'Airline', 'Aircraft Type']] = airline_fleet_df[\n",
    "#     ['Parent Airline', 'Airline', 'Aircraft Type']\n",
    "# ].fillna('Unknown')\n",
    "\n",
    "# # Convert cost columns to numeric by removing '$' and ','\n",
    "# airline_fleet_df['Unit Cost'] = (\n",
    "#     airline_fleet_df['Unit Cost'].replace({'\\$': '', ',': ''}, regex=True).astype(float)\n",
    "# )\n",
    "# airline_fleet_df['Total Cost (Current)'] = (\n",
    "#     airline_fleet_df['Total Cost (Current)'].replace({'\\$': '', ',': ''}, regex=True).astype(float)\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_merged = airline_fleet_df.merge(\n",
    "    airline_codes_df,\n",
    "    left_on='Airline',   # List format for multiple columns\n",
    "    right_on='Airline',         # List format for multiple columns\n",
    "    how='left'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_merged = airline_merged.merge(\n",
    "    airline_prices_df,\n",
    "    left_on='IATA',   # List format for multiple columns\n",
    "    right_on='car',         # List format for multiple columns\n",
    "    how='inner'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_merged['state'] = airline_merged['city2'].str.split(\", \").str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0_x', 'Parent Airline', 'Airline', 'Aircraft Type', 'Current',\n",
       "       'Historic', 'Unit Cost', 'Average Age', 'Unnamed: 0_y', 'IATA', 'ICAO',\n",
       "       'Unnamed: 0', 'mkt_fare', 'citymarketid_1', 'citymarketid_2', 'city1',\n",
       "       'city2', 'carairlineid', 'car', 'carpax', 'carpaxshare', 'Date',\n",
       "       'state'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_merged.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MERGE BELOW AFTER CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocess import DataPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Selecting relevant columns\n",
    "# needed_columns = [\n",
    "# 'IATA', 'Total', 'Orders', 'Unit Cost', 'Total Cost (Current)', 'Average Age','state'\n",
    "# ]\n",
    "\n",
    "# airline_merged = airline_merged[needed_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3355730"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0_x', 'FL_DATE', 'AIRLINE', 'AIRLINE_CODE', 'DOT_CODE',\n",
       "       'FL_NUMBER', 'ORIGIN', 'ORIGIN_CITY', 'DEST', 'DEST_CITY',\n",
       "       'CRS_DEP_TIME', 'DEP_DELAY', 'CRS_ARR_TIME', 'ARR_DELAY', 'CANCELLED',\n",
       "       'DIVERTED', 'CRS_ELAPSED_TIME', 'ELAPSED_TIME', 'AIR_TIME', 'DISTANCE',\n",
       "       'DELAY_DUE_CARRIER', 'DELAY_DUE_WEATHER', 'DELAY_DUE_NAS',\n",
       "       'DELAY_DUE_SECURITY', 'DELAY_DUE_LATE_AIRCRAFT', 'Month_Year', 'year_x',\n",
       "       'Unnamed: 0_y', 'data_dte', 'Year', 'Month', 'usg_apt_id', 'usg_apt',\n",
       "       'usg_wac', 'fg_apt_id', 'fg_apt', 'fg_wac', 'airlineid', 'carrier',\n",
       "       'carriergroup', 'type', 'Scheduled', 'Charter', 'date_x', 'year_y',\n",
       "       'state', 'Unnamed: 0', 'BEGIN_DATE_TIME', 'END_DATE_TIME', 'STATE',\n",
       "       'EVENT_TYPE', 'MAGNITUDE', 'INJURIES_DIRECT', 'INJURIES_INDIRECT',\n",
       "       'DEATHS_DIRECT', 'DEATHS_INDIRECT', 'date_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Selecting relevant columns\n",
    "# needed_columns = [\n",
    "# 'FL_DATE', 'AIRLINE_CODE', 'state', 'ARR_DELAY', 'CANCELLED',\n",
    "#        'DIVERTED', 'CRS_ELAPSED_TIME', 'DISTANCE','INJURIES_DIRECT', 'INJURIES_INDIRECT',\n",
    "#        'DEATHS_DIRECT', 'DEATHS_INDIRECT', 'DAMAGE_PROPERTY', 'DAMAGE_CROPS',\n",
    "#        'MAGNITUDE', 'MAGNITUDE_TYPE', 'FLOOD_CAUSE', 'CATEGORY'\n",
    "# ]\n",
    "\n",
    "# merged_df = merged_df[needed_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harshgupta/Desktop/Spring 2025/IDS/Project/cap5771sp25-project/Scripts/data_preprocess.py:110: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  z_scores = zscore(col_data)\n",
      "/Users/harshgupta/Desktop/Spring 2025/IDS/Project/cap5771sp25-project/Scripts/data_preprocess.py:110: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  z_scores = zscore(col_data)\n",
      "/Users/harshgupta/Desktop/Spring 2025/IDS/Project/cap5771sp25-project/Scripts/data_preprocess.py:110: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  z_scores = zscore(col_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 1701967 rows flagged as outliers across numeric columns.\n"
     ]
    }
   ],
   "source": [
    "final_df = DataPreprocessor(merged_df).handle_outliers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0_x', 'FL_DATE', 'AIRLINE', 'AIRLINE_CODE', 'DOT_CODE',\n",
       "       'FL_NUMBER', 'ORIGIN', 'ORIGIN_CITY', 'DEST', 'DEST_CITY',\n",
       "       'CRS_DEP_TIME', 'DEP_DELAY', 'CRS_ARR_TIME', 'ARR_DELAY', 'CANCELLED',\n",
       "       'DIVERTED', 'CRS_ELAPSED_TIME', 'ELAPSED_TIME', 'AIR_TIME', 'DISTANCE',\n",
       "       'DELAY_DUE_CARRIER', 'DELAY_DUE_WEATHER', 'DELAY_DUE_NAS',\n",
       "       'DELAY_DUE_SECURITY', 'DELAY_DUE_LATE_AIRCRAFT', 'Month_Year', 'year_x',\n",
       "       'Unnamed: 0_y', 'data_dte', 'Year', 'Month', 'usg_apt_id', 'usg_apt',\n",
       "       'usg_wac', 'fg_apt_id', 'fg_apt', 'fg_wac', 'airlineid', 'carrier',\n",
       "       'carriergroup', 'type', 'Scheduled', 'Charter', 'date_x', 'year_y',\n",
       "       'state', 'Unnamed: 0', 'BEGIN_DATE_TIME', 'END_DATE_TIME', 'STATE',\n",
       "       'EVENT_TYPE', 'MAGNITUDE', 'INJURIES_DIRECT', 'INJURIES_INDIRECT',\n",
       "       'DEATHS_DIRECT', 'DEATHS_INDIRECT', 'date_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df.to_csv('data/merged_df.csv', index=False)\n",
    "# airline_merged.to_csv('data/airline_merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0_x                    0\n",
      "FL_DATE                         0\n",
      "AIRLINE                         0\n",
      "AIRLINE_CODE                    0\n",
      "DOT_CODE                        0\n",
      "FL_NUMBER                       0\n",
      "ORIGIN                          0\n",
      "ORIGIN_CITY                     0\n",
      "DEST                            0\n",
      "DEST_CITY                       0\n",
      "CRS_DEP_TIME                    0\n",
      "DEP_DELAY                       0\n",
      "CRS_ARR_TIME                    0\n",
      "ARR_DELAY                       0\n",
      "CANCELLED                       0\n",
      "DIVERTED                        0\n",
      "CRS_ELAPSED_TIME                0\n",
      "ELAPSED_TIME                    0\n",
      "AIR_TIME                        0\n",
      "DISTANCE                        0\n",
      "DELAY_DUE_CARRIER               0\n",
      "DELAY_DUE_WEATHER               0\n",
      "DELAY_DUE_NAS                   0\n",
      "DELAY_DUE_SECURITY              0\n",
      "DELAY_DUE_LATE_AIRCRAFT         0\n",
      "Month_Year                      0\n",
      "year_x                          0\n",
      "Unnamed: 0_y               149531\n",
      "data_dte                   149531\n",
      "Year                       149531\n",
      "Month                      149531\n",
      "usg_apt_id                 149531\n",
      "usg_apt                    149531\n",
      "usg_wac                    149531\n",
      "fg_apt_id                  149531\n",
      "fg_apt                     149531\n",
      "fg_wac                     149531\n",
      "airlineid                  149531\n",
      "carrier                    149531\n",
      "carriergroup               149531\n",
      "type                       149531\n",
      "Scheduled                  149531\n",
      "Charter                    149531\n",
      "date_x                     149531\n",
      "year_y                     149531\n",
      "state                           0\n",
      "Unnamed: 0                      0\n",
      "BEGIN_DATE_TIME                 0\n",
      "END_DATE_TIME                   0\n",
      "STATE                           0\n",
      "EVENT_TYPE                      0\n",
      "MAGNITUDE                       0\n",
      "INJURIES_DIRECT                 0\n",
      "INJURIES_INDIRECT               0\n",
      "DEATHS_DIRECT                   0\n",
      "DEATHS_INDIRECT                 0\n",
      "date_y                          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "null_counts = merged_df.isnull().sum()\n",
    "print(null_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_df = merged_df.dropna(subset=['MAGNITUDE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3355730"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_merged_df.to_csv('data/final_merged_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60256"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(airline_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_merged = airline_merged.drop_duplicates(subset=['Unit Cost', 'IATA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_merged' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfinal_merged\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../Data/pre_final_merged.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_merged' is not defined"
     ]
    }
   ],
   "source": [
    "final_merged_df.to_csv(\"../Data/pre_final_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "final_merged = final_merged_df.merge(\n",
    "    airline_merged,\n",
    "    left_on=['state','AIRLINE_CODE'],   # List format for multiple columns\n",
    "    right_on=['state','IATA'],         # List format for multiple columns\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FL_DATE', 'AIRLINE_CODE', 'state', 'ARR_DELAY', 'CANCELLED',\n",
       "       'DIVERTED', 'CRS_ELAPSED_TIME', 'DISTANCE', 'INJURIES_DIRECT',\n",
       "       'INJURIES_INDIRECT', 'DEATHS_DIRECT', 'DEATHS_INDIRECT',\n",
       "       'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'MAGNITUDE', 'MAGNITUDE_TYPE',\n",
       "       'FLOOD_CAUSE', 'CATEGORY', 'IATA', 'Total', 'Orders', 'Unit Cost',\n",
       "       'Total Cost (Current)', 'Average Age'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_merged.dropna(subset=['FL_DATE','AIRLINE_CODE','state','MAGNITUDE','Average Age'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "548849"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatetimeArray>\n",
       "['2020-07-31 00:00:00', '2020-03-28 00:00:00', '2020-04-29 00:00:00',\n",
       " '2020-10-26 00:00:00', '2020-08-19 00:00:00', '2020-11-09 00:00:00',\n",
       " '2020-09-28 00:00:00', '2020-07-29 00:00:00', '2020-02-09 00:00:00',\n",
       " '2020-06-24 00:00:00',\n",
       " ...\n",
       " '2020-11-12 00:00:00', '2020-09-19 00:00:00', '2020-02-29 00:00:00',\n",
       " '2020-12-28 00:00:00', '2020-06-07 00:00:00', '2020-01-08 00:00:00',\n",
       " '2020-04-21 00:00:00', '2020-04-20 00:00:00', '2020-05-14 00:00:00',\n",
       " '2020-12-03 00:00:00']\n",
       "Length: 248, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged['FL_DATE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\florida_coursework\\second_sem\\intro_to_data_science\\ids_env\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\florida_coursework\\second_sem\\intro_to_data_science\\ids_env\\Lib\\site-packages\\numpy\\_core\\_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 247831 rows flagged as outliers across numeric columns.\n"
     ]
    }
   ],
   "source": [
    "prod_final = DataPreprocessor(final_merged).handle_outliers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301018"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prod_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
